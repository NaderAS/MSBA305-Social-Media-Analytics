{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26a49c3",
   "metadata": {},
   "source": [
    "In this Notebook we fetch Reddit posts and comments using Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f329698f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (7.8.1)\n",
      "Requirement already satisfied: update_checker>=0.18 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# installing required libraries\n",
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "# Setup Reddit API\n",
    "def setup_reddit_api(client_id, client_secret, user_agent):\n",
    "    \"\"\"Set up Reddit API client.\"\"\"\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=client_id,\n",
    "        client_secret=client_secret,\n",
    "        user_agent=user_agent\n",
    "    )\n",
    "    return reddit\n",
    "\n",
    "# Infer content type (text, image, video, link, other)\n",
    "def infer_content_type(post):\n",
    "    if post.is_self:\n",
    "        return \"text\"\n",
    "    elif hasattr(post, \"post_hint\"):\n",
    "        if post.post_hint == \"image\":\n",
    "            return \"image\"\n",
    "        elif post.post_hint in [\"hosted:video\", \"rich:video\"] or post.is_video:\n",
    "            return \"video\"\n",
    "        elif post.post_hint == \"link\":\n",
    "            return \"link\"\n",
    "    elif post.url.endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "        return \"image\"\n",
    "    elif \"v.redd.it\" in post.url:\n",
    "        return \"video\"\n",
    "    return \"other\"\n",
    "\n",
    "# Get posts from a subreddit (with content_type)\n",
    "def get_subreddit_posts(reddit, subreddit_name, limit=400):\n",
    "    \"\"\"Get posts from a subreddit.\"\"\"\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    posts = []\n",
    "\n",
    "    for post in subreddit.hot(limit=limit):\n",
    "        posts.append({\n",
    "            'post_id': post.id,\n",
    "            'title': post.title,\n",
    "            'text': post.selftext,\n",
    "            'author': str(post.author),\n",
    "            'created_utc': post.created_utc,\n",
    "            'score': post.score,\n",
    "            'num_comments': post.num_comments,\n",
    "            'upvote_ratio': post.upvote_ratio,\n",
    "            'content_type': infer_content_type(post) \n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(posts)\n",
    "\n",
    "# Get comments for a specific post\n",
    "def get_post_comments(reddit, post_id, limit=400):\n",
    "    \"\"\"Get comments for a specific post.\"\"\"\n",
    "    post = reddit.submission(id=post_id)\n",
    "    post.comments.replace_more(limit=0) \n",
    "    comments = []\n",
    "\n",
    "    for comment in post.comments[:limit]:\n",
    "        comments.append({\n",
    "            'comment_id': comment.id,\n",
    "            'post_id': post_id,\n",
    "            'author': str(comment.author),\n",
    "            'text': comment.body,\n",
    "            'score': comment.score,\n",
    "            'created_utc': comment.created_utc\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "052def9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Reddit API\n",
    "client_id = \"YI3yiSbD9yctHZ2NMIQoZA\"\n",
    "client_secret = \"vZ1MFPXuDEXCe-NaEwEyKnDrKyaPyg\"\n",
    "user_agent = \"script : data_collection :v1 .0 (by/u/data_collection)\"\n",
    "reddit = setup_reddit_api( client_id , client_secret , user_agent )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3436924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>content_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1k44mgg</td>\n",
       "      <td>Weekly Entering &amp; Transitioning - Thread 21 Ap...</td>\n",
       "      <td>\\n\\nWelcome to this week's entering &amp; transit...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>1.745208e+09</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1i5inrb</td>\n",
       "      <td>Weekly Entering &amp; Transitioning - Thread 20 Ja...</td>\n",
       "      <td>\\n\\nWelcome to this week's entering &amp; transit...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>1.737349e+09</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>1.00</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1k6tz9y</td>\n",
       "      <td>Leadership said they doesn’t understand what w...</td>\n",
       "      <td>Our DS group was moved under a traditional IT ...</td>\n",
       "      <td>DeepNarwhalNetwork</td>\n",
       "      <td>1.745506e+09</td>\n",
       "      <td>63</td>\n",
       "      <td>34</td>\n",
       "      <td>0.92</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1k6wi45</td>\n",
       "      <td>What are some universities that you believe ar...</td>\n",
       "      <td></td>\n",
       "      <td>Voldemort57</td>\n",
       "      <td>1.745512e+09</td>\n",
       "      <td>14</td>\n",
       "      <td>43</td>\n",
       "      <td>0.72</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1k6rj0y</td>\n",
       "      <td>Deep Analysis — the analytics analogue to deep...</td>\n",
       "      <td></td>\n",
       "      <td>phicreative1997</td>\n",
       "      <td>1.745499e+09</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                              title  \\\n",
       "0  1k44mgg  Weekly Entering & Transitioning - Thread 21 Ap...   \n",
       "1  1i5inrb  Weekly Entering & Transitioning - Thread 20 Ja...   \n",
       "2  1k6tz9y  Leadership said they doesn’t understand what w...   \n",
       "3  1k6wi45  What are some universities that you believe ar...   \n",
       "4  1k6rj0y  Deep Analysis — the analytics analogue to deep...   \n",
       "\n",
       "                                                text              author  \\\n",
       "0   \\n\\nWelcome to this week's entering & transit...       AutoModerator   \n",
       "1   \\n\\nWelcome to this week's entering & transit...       AutoModerator   \n",
       "2  Our DS group was moved under a traditional IT ...  DeepNarwhalNetwork   \n",
       "3                                                            Voldemort57   \n",
       "4                                                        phicreative1997   \n",
       "\n",
       "    created_utc  score  num_comments  upvote_ratio content_type  \n",
       "0  1.745208e+09      7            18          1.00         text  \n",
       "1  1.737349e+09     13            46          1.00         text  \n",
       "2  1.745506e+09     63            34          0.92         text  \n",
       "3  1.745512e+09     14            43          0.72        other  \n",
       "4  1.745499e+09      5             0          0.78         link  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Reddit posts\n",
    "import os\n",
    "\n",
    "posts_df_reddit = get_subreddit_posts(reddit , \"datascience\" , limit =300)\n",
    "\n",
    "output_dir = '../reddit_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# save posts_df_reddit to csv\n",
    "posts_df_reddit.to_csv(f'{output_dir}/reddit_posts_df.csv', index=False)\n",
    "\n",
    "# view posts_df_reddit\n",
    "posts_df_reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00749389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Retrieved 1 comments for post: 1k44mgg\n",
      "✅ Retrieved 24 comments for post: 1i5inrb\n",
      "✅ Retrieved 39 comments for post: 1k4geso\n",
      "✅ Retrieved 93 comments for post: 1k3nxj7\n",
      "✅ Retrieved 4 comments for post: 1k3e4nb\n",
      "✅ Retrieved 23 comments for post: 1k32lrl\n",
      "✅ Retrieved 1 comments for post: 1k3jt7b\n",
      "✅ Retrieved 13 comments for post: 1k2y84g\n",
      "✅ Retrieved 2 comments for post: 1k33k6t\n",
      "✅ Retrieved 7 comments for post: 1k35lig\n",
      "✅ Retrieved 12 comments for post: 1k2igce\n",
      "✅ Retrieved 1 comments for post: 1k2u4nd\n",
      "✅ Retrieved 32 comments for post: 1k26kp3\n",
      "✅ Retrieved 4 comments for post: 1k2a8t6\n",
      "✅ Retrieved 34 comments for post: 1k26920\n",
      "✅ Retrieved 9 comments for post: 1k2ax74\n",
      "✅ Retrieved 19 comments for post: 1k22cd4\n",
      "✅ Retrieved 13 comments for post: 1k1wu9o\n",
      "✅ Retrieved 11 comments for post: 1k1mjok\n",
      "✅ Retrieved 4 comments for post: 1k1x464\n",
      "✅ Retrieved 1 comments for post: 1k1vo23\n",
      "✅ Retrieved 4 comments for post: 1k1lh3r\n",
      "✅ Retrieved 1 comments for post: 1k1ohsp\n",
      "✅ Retrieved 5 comments for post: 1k20azb\n",
      "✅ Retrieved 21 comments for post: 1k0zcye\n",
      "✅ Retrieved 11 comments for post: 1k0v0dc\n",
      "✅ Retrieved 72 comments for post: 1k0c459\n",
      "✅ Retrieved 23 comments for post: 1k0mdr3\n",
      "✅ Retrieved 2 comments for post: 1k0vdku\n",
      "✅ Retrieved 9 comments for post: 1k082ij\n",
      "✅ Retrieved 28 comments for post: 1jzml32\n",
      "✅ Retrieved 5 comments for post: 1jz0h1y\n",
      "✅ Retrieved 29 comments for post: 1jz4teg\n",
      "✅ Retrieved 26 comments for post: 1jyu503\n",
      "✅ Retrieved 25 comments for post: 1jyicx6\n",
      "✅ Retrieved 13 comments for post: 1jyloqi\n",
      "✅ Retrieved 24 comments for post: 1jyq1tk\n",
      "✅ Retrieved 42 comments for post: 1jy2pe0\n",
      "✅ Retrieved 13 comments for post: 1jxl18x\n",
      "✅ Retrieved 10 comments for post: 1jxtzs1\n",
      "✅ Retrieved 25 comments for post: 1jxdlfg\n",
      "✅ Retrieved 4 comments for post: 1jygakg\n",
      "✅ Retrieved 5 comments for post: 1jxk5za\n",
      "✅ Retrieved 3 comments for post: 1jxe7rg\n",
      "✅ Retrieved 41 comments for post: 1jwbevk\n",
      "✅ Retrieved 10 comments for post: 1jwlf3f\n",
      "✅ Retrieved 9 comments for post: 1jx5k15\n",
      "✅ Retrieved 4 comments for post: 1jwduc6\n",
      "✅ Retrieved 6 comments for post: 1jw7i9l\n",
      "✅ Retrieved 3 comments for post: 1jvrgr5\n",
      "💾 All comments saved to reddit_data/reddit_post_comments.csv\n"
     ]
    }
   ],
   "source": [
    "# Fetch comments for all posts in posts_df_reddit\n",
    "all_comments = []\n",
    "\n",
    "for post_id in posts_df_reddit['post_id']:\n",
    "    try:\n",
    "        comments_df = get_post_comments(reddit, post_id, limit=300)\n",
    "        all_comments.append(comments_df)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to fetch comments for {post_id}: {e}\")\n",
    "\n",
    "# Combine all comments into a single DataFrame\n",
    "all_comments_df = pd.concat(all_comments, ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "all_comments_df.to_csv(\"../reddit_data/reddit_post_comments.csv\", index=False)\n",
    "print(\"💾 All comments saved to reddit_data/reddit_post_comments.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa23535d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m8l6gbd</td>\n",
       "      <td>1i5inrb</td>\n",
       "      <td>dogdiarrhea</td>\n",
       "      <td>Nonstandard transition question: how many peop...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.737573e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m8wl92v</td>\n",
       "      <td>1i5inrb</td>\n",
       "      <td>Left-Animal1559</td>\n",
       "      <td>I am a senior talent partner with Swish Analyt...</td>\n",
       "      <td>6</td>\n",
       "      <td>1.737725e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m8y2o1w</td>\n",
       "      <td>1i5inrb</td>\n",
       "      <td>doorstoinfinity</td>\n",
       "      <td>Hi everyone!\\n\\nI'm transitioning from Data An...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.737741e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m84ed38</td>\n",
       "      <td>1i5inrb</td>\n",
       "      <td>Silent_Group6621</td>\n",
       "      <td>Can someone suggest me some DS/Analytics/ML pr...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.737354e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m85eg48</td>\n",
       "      <td>1i5inrb</td>\n",
       "      <td>j-unnlock</td>\n",
       "      <td>Here's a list of job boards I'm working on ser...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.737376e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  post_id            author  \\\n",
       "0    m8l6gbd  1i5inrb       dogdiarrhea   \n",
       "1    m8wl92v  1i5inrb   Left-Animal1559   \n",
       "2    m8y2o1w  1i5inrb   doorstoinfinity   \n",
       "3    m84ed38  1i5inrb  Silent_Group6621   \n",
       "4    m85eg48  1i5inrb         j-unnlock   \n",
       "\n",
       "                                                text  score   created_utc  \n",
       "0  Nonstandard transition question: how many peop...      5  1.737573e+09  \n",
       "1  I am a senior talent partner with Swish Analyt...      6  1.737725e+09  \n",
       "2  Hi everyone!\\n\\nI'm transitioning from Data An...      4  1.737741e+09  \n",
       "3  Can someone suggest me some DS/Analytics/ML pr...      3  1.737354e+09  \n",
       "4  Here's a list of job boards I'm working on ser...      2  1.737376e+09  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_comments_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-clean)",
   "language": "python",
   "name": "tf-clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
