{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d26a49c3",
   "metadata": {},
   "source": [
    "In this Notebook we fetch Reddit posts and comments using Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f329698f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: praw in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (7.8.1)\n",
      "Requirement already satisfied: update_checker>=0.18 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from praw) (0.18.0)\n",
      "Requirement already satisfied: prawcore<3,>=2.4 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from praw) (2.4.0)\n",
      "Requirement already satisfied: websocket-client>=0.54.0 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from praw) (1.8.0)\n",
      "Requirement already satisfied: requests<3.0,>=2.6.0 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\maisoonabofakher\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# installing required libraries\n",
    "!pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd91fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "# Setup Reddit API\n",
    "def setup_reddit_api(client_id, client_secret, user_agent):\n",
    "    \"\"\"Set up Reddit API client.\"\"\"\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=client_id,\n",
    "        client_secret=client_secret,\n",
    "        user_agent=user_agent\n",
    "    )\n",
    "    return reddit\n",
    "\n",
    "# Infer content type (text, image, video, link, other)\n",
    "def infer_content_type(post):\n",
    "    if post.is_self:\n",
    "        return \"text\"\n",
    "    elif hasattr(post, \"post_hint\"):\n",
    "        if post.post_hint == \"image\":\n",
    "            return \"image\"\n",
    "        elif post.post_hint in [\"hosted:video\", \"rich:video\"] or post.is_video:\n",
    "            return \"video\"\n",
    "        elif post.post_hint == \"link\":\n",
    "            return \"link\"\n",
    "    elif post.url.endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "        return \"image\"\n",
    "    elif \"v.redd.it\" in post.url:\n",
    "        return \"video\"\n",
    "    return \"other\"\n",
    "\n",
    "# Get posts from a subreddit (with content_type)\n",
    "def get_subreddit_posts(reddit, subreddit_name, limit=400):\n",
    "    \"\"\"Get posts from a subreddit.\"\"\"\n",
    "    subreddit = reddit.subreddit(subreddit_name)\n",
    "    posts = []\n",
    "\n",
    "    for post in subreddit.hot(limit=limit):\n",
    "        posts.append({\n",
    "            'post_id': post.id,\n",
    "            'title': post.title,\n",
    "            'text': post.selftext,\n",
    "            'author': str(post.author),\n",
    "            'created_utc': post.created_utc,\n",
    "            'score': post.score,\n",
    "            'num_comments': post.num_comments,\n",
    "            'upvote_ratio': post.upvote_ratio,\n",
    "            'content_type': infer_content_type(post) \n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(posts)\n",
    "\n",
    "# Get comments for a specific post\n",
    "def get_post_comments(reddit, post_id, limit=400):\n",
    "    \"\"\"Get comments for a specific post.\"\"\"\n",
    "    post = reddit.submission(id=post_id)\n",
    "    post.comments.replace_more(limit=0) \n",
    "    comments = []\n",
    "\n",
    "    for comment in post.comments[:limit]:\n",
    "        comments.append({\n",
    "            'comment_id': comment.id,\n",
    "            'post_id': post_id,\n",
    "            'author': str(comment.author),\n",
    "            'text': comment.body,\n",
    "            'score': comment.score,\n",
    "            'created_utc': comment.created_utc\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "052def9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Reddit API\n",
    "client_id = \"YI3yiSbD9yctHZ2NMIQoZA\"\n",
    "client_secret = \"vZ1MFPXuDEXCe-NaEwEyKnDrKyaPyg\"\n",
    "user_agent = \"script : data_collection :v1 .0 (by/u/data_collection)\"\n",
    "reddit = setup_reddit_api( client_id , client_secret , user_agent )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3436924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>upvote_ratio</th>\n",
       "      <th>content_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1k44mgg</td>\n",
       "      <td>Weekly Entering &amp; Transitioning - Thread 21 Ap...</td>\n",
       "      <td>\\n\\nWelcome to this week's entering &amp; transit...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>1.745208e+09</td>\n",
       "      <td>7</td>\n",
       "      <td>18</td>\n",
       "      <td>1.00</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1i5inrb</td>\n",
       "      <td>Weekly Entering &amp; Transitioning - Thread 20 Ja...</td>\n",
       "      <td>\\n\\nWelcome to this week's entering &amp; transit...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>1.737349e+09</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>1.00</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1k6tz9y</td>\n",
       "      <td>Leadership said they doesn‚Äôt understand what w...</td>\n",
       "      <td>Our DS group was moved under a traditional IT ...</td>\n",
       "      <td>DeepNarwhalNetwork</td>\n",
       "      <td>1.745506e+09</td>\n",
       "      <td>63</td>\n",
       "      <td>34</td>\n",
       "      <td>0.92</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1k6wi45</td>\n",
       "      <td>What are some universities that you believe ar...</td>\n",
       "      <td></td>\n",
       "      <td>Voldemort57</td>\n",
       "      <td>1.745512e+09</td>\n",
       "      <td>14</td>\n",
       "      <td>43</td>\n",
       "      <td>0.72</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1k6rj0y</td>\n",
       "      <td>Deep Analysis‚Ää‚Äî‚Ääthe analytics analogue to deep...</td>\n",
       "      <td></td>\n",
       "      <td>phicreative1997</td>\n",
       "      <td>1.745499e+09</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.78</td>\n",
       "      <td>link</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                              title  \\\n",
       "0  1k44mgg  Weekly Entering & Transitioning - Thread 21 Ap...   \n",
       "1  1i5inrb  Weekly Entering & Transitioning - Thread 20 Ja...   \n",
       "2  1k6tz9y  Leadership said they doesn‚Äôt understand what w...   \n",
       "3  1k6wi45  What are some universities that you believe ar...   \n",
       "4  1k6rj0y  Deep Analysis‚Ää‚Äî‚Ääthe analytics analogue to deep...   \n",
       "\n",
       "                                                text              author  \\\n",
       "0   \\n\\nWelcome to this week's entering & transit...       AutoModerator   \n",
       "1   \\n\\nWelcome to this week's entering & transit...       AutoModerator   \n",
       "2  Our DS group was moved under a traditional IT ...  DeepNarwhalNetwork   \n",
       "3                                                            Voldemort57   \n",
       "4                                                        phicreative1997   \n",
       "\n",
       "    created_utc  score  num_comments  upvote_ratio content_type  \n",
       "0  1.745208e+09      7            18          1.00         text  \n",
       "1  1.737349e+09     13            46          1.00         text  \n",
       "2  1.745506e+09     63            34          0.92         text  \n",
       "3  1.745512e+09     14            43          0.72        other  \n",
       "4  1.745499e+09      5             0          0.78         link  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Reddit posts\n",
    "import os\n",
    "\n",
    "posts_df_reddit = get_subreddit_posts(reddit , \"datascience\" , limit =300)\n",
    "\n",
    "output_dir = '../reddit_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# save posts_df_reddit to csv\n",
    "posts_df_reddit.to_csv(f'{output_dir}/reddit_posts_df.csv', index=False)\n",
    "\n",
    "# view posts_df_reddit\n",
    "posts_df_reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00749389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retrieved 1 comments for post: 1k44mgg\n",
      "‚úÖ Retrieved 24 comments for post: 1i5inrb\n",
      "‚úÖ Retrieved 39 comments for post: 1k4geso\n",
      "‚úÖ Retrieved 93 comments for post: 1k3nxj7\n",
      "‚úÖ Retrieved 4 comments for post: 1k3e4nb\n",
      "‚úÖ Retrieved 23 comments for post: 1k32lrl\n",
      "‚úÖ Retrieved 1 comments for post: 1k3jt7b\n",
      "‚úÖ Retrieved 13 comments for post: 1k2y84g\n",
      "‚úÖ Retrieved 2 comments for post: 1k33k6t\n",
      "‚úÖ Retrieved 7 comments for post: 1k35lig\n",
      "‚úÖ Retrieved 12 comments for post: 1k2igce\n",
      "‚úÖ Retrieved 1 comments for post: 1k2u4nd\n",
      "‚úÖ Retrieved 32 comments for post: 1k26kp3\n",
      "‚úÖ Retrieved 4 comments for post: 1k2a8t6\n",
      "‚úÖ Retrieved 34 comments for post: 1k26920\n",
      "‚úÖ Retrieved 9 comments for post: 1k2ax74\n",
      "‚úÖ Retrieved 19 comments for post: 1k22cd4\n",
      "‚úÖ Retrieved 13 comments for post: 1k1wu9o\n",
      "‚úÖ Retrieved 11 comments for post: 1k1mjok\n",
      "‚úÖ Retrieved 4 comments for post: 1k1x464\n",
      "‚úÖ Retrieved 1 comments for post: 1k1vo23\n",
      "‚úÖ Retrieved 4 comments for post: 1k1lh3r\n",
      "‚úÖ Retrieved 1 comments for post: 1k1ohsp\n",
      "‚úÖ Retrieved 5 comments for post: 1k20azb\n",
      "‚úÖ Retrieved 21 comments for post: 1k0zcye\n",
      "‚úÖ Retrieved 11 comments for post: 1k0v0dc\n",
      "‚úÖ Retrieved 72 comments for post: 1k0c459\n",
      "‚úÖ Retrieved 23 comments for post: 1k0mdr3\n",
      "‚úÖ Retrieved 2 comments for post: 1k0vdku\n",
      "‚úÖ Retrieved 9 comments for post: 1k082ij\n",
      "‚úÖ Retrieved 28 comments for post: 1jzml32\n",
      "‚úÖ Retrieved 5 comments for post: 1jz0h1y\n",
      "‚úÖ Retrieved 29 comments for post: 1jz4teg\n",
      "‚úÖ Retrieved 26 comments for post: 1jyu503\n",
      "‚úÖ Retrieved 25 comments for post: 1jyicx6\n",
      "‚úÖ Retrieved 13 comments for post: 1jyloqi\n",
      "‚úÖ Retrieved 24 comments for post: 1jyq1tk\n",
      "‚úÖ Retrieved 42 comments for post: 1jy2pe0\n",
      "‚úÖ Retrieved 13 comments for post: 1jxl18x\n",
      "‚úÖ Retrieved 10 comments for post: 1jxtzs1\n",
      "‚úÖ Retrieved 25 comments for post: 1jxdlfg\n",
      "‚úÖ Retrieved 4 comments for post: 1jygakg\n",
      "‚úÖ Retrieved 5 comments for post: 1jxk5za\n",
      "‚úÖ Retrieved 3 comments for post: 1jxe7rg\n",
      "‚úÖ Retrieved 41 comments for post: 1jwbevk\n",
      "‚úÖ Retrieved 10 comments for post: 1jwlf3f\n",
      "‚úÖ Retrieved 9 comments for post: 1jx5k15\n",
      "‚úÖ Retrieved 4 comments for post: 1jwduc6\n",
      "‚úÖ Retrieved 6 comments for post: 1jw7i9l\n",
      "‚úÖ Retrieved 3 comments for post: 1jvrgr5\n",
      "üíæ All comments saved to reddit_data/reddit_post_comments.csv\n"
     ]
    }
   ],
   "source": [
    "# Fetch comments for all posts in posts_df_reddit\n",
    "all_comments = []\n",
    "\n",
    "for post_id in posts_df_reddit['post_id']:\n",
    "    try:\n",
    "        comments_df = get_post_comments(reddit, post_id, limit=300)\n",
    "        all_comments.append(comments_df)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to fetch comments for {post_id}: {e}\")\n",
    "\n",
    "# Combine all comments into a single DataFrame\n",
    "all_comments_df = pd.concat(all_comments, ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "all_comments_df.to_csv(\"../reddit_data/reddit_post_comments.csv\", index=False)\n",
    "print(\"üíæ All comments saved to reddit_data/reddit_post_comments.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa23535d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>created_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m8l6gbd</td>\n",
       "      <td>1i5inrb</td>\n",
       "      <td>dogdiarrhea</td>\n",
       "      <td>Nonstandard transition question: how many peop...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.737573e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m8wl92v</td>\n",
       "      <td>1i5inrb</td>\n",
       "      <td>Left-Animal1559</td>\n",
       "      <td>I am a senior talent partner with Swish Analyt...</td>\n",
       "      <td>6</td>\n",
       "      <td>1.737725e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m8y2o1w</td>\n",
       "      <td>1i5inrb</td>\n",
       "      <td>doorstoinfinity</td>\n",
       "      <td>Hi everyone!\\n\\nI'm transitioning from Data An...</td>\n",
       "      <td>4</td>\n",
       "      <td>1.737741e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m84ed38</td>\n",
       "      <td>1i5inrb</td>\n",
       "      <td>Silent_Group6621</td>\n",
       "      <td>Can someone suggest me some DS/Analytics/ML pr...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.737354e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m85eg48</td>\n",
       "      <td>1i5inrb</td>\n",
       "      <td>j-unnlock</td>\n",
       "      <td>Here's a list of job boards I'm working on ser...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.737376e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  post_id            author  \\\n",
       "0    m8l6gbd  1i5inrb       dogdiarrhea   \n",
       "1    m8wl92v  1i5inrb   Left-Animal1559   \n",
       "2    m8y2o1w  1i5inrb   doorstoinfinity   \n",
       "3    m84ed38  1i5inrb  Silent_Group6621   \n",
       "4    m85eg48  1i5inrb         j-unnlock   \n",
       "\n",
       "                                                text  score   created_utc  \n",
       "0  Nonstandard transition question: how many peop...      5  1.737573e+09  \n",
       "1  I am a senior talent partner with Swish Analyt...      6  1.737725e+09  \n",
       "2  Hi everyone!\\n\\nI'm transitioning from Data An...      4  1.737741e+09  \n",
       "3  Can someone suggest me some DS/Analytics/ML pr...      3  1.737354e+09  \n",
       "4  Here's a list of job boards I'm working on ser...      2  1.737376e+09  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_comments_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-clean)",
   "language": "python",
   "name": "tf-clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
