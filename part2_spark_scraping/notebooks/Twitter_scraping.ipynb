{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this Notebook we fetch Twitter tweets and users using Twitter API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTHwSxQ2Vacw",
        "outputId": "74edb20f-ba48-499a-c0c6-624b7f75de88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Searching for tweets about 'data science'...\n",
            "Found 100 tweets\n",
            "These tweets were created by 89 unique authors\n",
            "Retrieved details for 89 users\n",
            "Saved tweet data to 'data_science_tweets.csv'\n",
            "Saved user data to 'data_science_users.csv'\n",
            "\n",
            "Sample of tweet data:\n",
            "              tweet_id                                               text  \\\n",
            "0  1913171407833379034  RT @omoalhajaabiola: Master in Business Analyt...   \n",
            "1  1913171220226277705  â†’ Context. \\nâ†’ Full datasets. \\nâ†’ The studies ...   \n",
            "2  1913171217328021684  I'm a scientist.  \\nEvery time I see a viral h...   \n",
            "\n",
            "                 created_at            author_id  retweet_count  reply_count  \\\n",
            "0 2025-04-18 10:03:03+00:00  1185728337873899520              6            0   \n",
            "1 2025-04-18 10:02:18+00:00            282965354              0            1   \n",
            "2 2025-04-18 10:02:17+00:00            282965354              0            1   \n",
            "\n",
            "   like_count  quote_count  \n",
            "0           0            0  \n",
            "1           0            0  \n",
            "2           0            0  \n",
            "\n",
            "Sample of user data:\n",
            "               user_id      name      username  followers_count  \\\n",
            "0  1185728337873899520  Dr_cupid    arthorjnr1              133   \n",
            "1  1912298092046802944   Vinayak  vinayakxlife                7   \n",
            "2  1890964286228353024       EBB  N3v3rR3tr3at              184   \n",
            "\n",
            "   following_count  tweet_count  \n",
            "0             1322         8423  \n",
            "1               43           30  \n",
            "2              780         3826  \n"
          ]
        }
      ],
      "source": [
        "import tweepy\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "def setup_twitter_api(bearer_token=\"AAAAAAAAAAAAAAAAAAAAAEVoywEAAAAA2vA7jxSZ3wNvckLTjgkMpVGOnk8%3DoghnW868H0RDSsf8x5wibHapA2kA3db2dgsSF5y3IPAxGSFh7E\"):\n",
        "    \"\"\"Set up Twitter API client.\"\"\"\n",
        "    client = tweepy.Client(bearer_token=bearer_token)\n",
        "    return client\n",
        "\n",
        "def search_tweets(client, query, max_results=100):\n",
        "    \"\"\"Search for tweets matching the query.\"\"\"\n",
        "    tweets = client.search_recent_tweets(\n",
        "        query=query,\n",
        "        max_results=max_results,\n",
        "        tweet_fields=['created_at', 'public_metrics', 'author_id']\n",
        "    )\n",
        "    return tweets.data\n",
        "\n",
        "def get_user_details(client, user_ids):\n",
        "    \"\"\"Get details about users by their IDs.\"\"\"\n",
        "    users = client.get_users(\n",
        "        ids=user_ids,\n",
        "        user_fields=['name', 'username', 'created_at', 'public_metrics']\n",
        "    )\n",
        "    return users.data\n",
        "\n",
        "def tweets_to_dataframe(tweets):\n",
        "    \"\"\"Convert tweet data to pandas DataFrame.\"\"\"\n",
        "    data = []\n",
        "    for tweet in tweets:\n",
        "        data.append({\n",
        "            'tweet_id': tweet.id,\n",
        "            'text': tweet.text,\n",
        "            'created_at': tweet.created_at,\n",
        "            'author_id': tweet.author_id,\n",
        "            'retweet_count': tweet.public_metrics['retweet_count'],\n",
        "            'reply_count': tweet.public_metrics['reply_count'],\n",
        "            'like_count': tweet.public_metrics['like_count'],\n",
        "            'quote_count': tweet.public_metrics['quote_count']\n",
        "        })\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "# Example usage of the script\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize API client with your bearer token\n",
        "    client = setup_twitter_api()\n",
        "\n",
        "    # Define search query\n",
        "    search_query = \"data science\"  # You can change this to any topic you want\n",
        "    max_results = 100  # Number of tweets to retrieve (max 100 per request)\n",
        "\n",
        "    print(f\"Searching for tweets about '{search_query}'...\")\n",
        "\n",
        "    # Search for tweets\n",
        "    tweets = search_tweets(client, search_query, max_results)\n",
        "\n",
        "    if tweets:\n",
        "        print(f\"Found {len(tweets)} tweets\")\n",
        "\n",
        "        # Extract unique author IDs from the tweets\n",
        "        author_ids = list(set([tweet.author_id for tweet in tweets]))\n",
        "        print(f\"These tweets were created by {len(author_ids)} unique authors\")\n",
        "\n",
        "        # Get user details for these authors\n",
        "        users = get_user_details(client, author_ids)\n",
        "\n",
        "        if users:\n",
        "            print(f\"Retrieved details for {len(users)} users\")\n",
        "\n",
        "            # Create a small dataframe of user information\n",
        "            user_data = []\n",
        "            for user in users:\n",
        "                user_data.append({\n",
        "                    'user_id': user.id,\n",
        "                    'name': user.name,\n",
        "                    'username': user.username,\n",
        "                    'followers_count': user.public_metrics['followers_count'],\n",
        "                    'following_count': user.public_metrics['following_count'],\n",
        "                    'tweet_count': user.public_metrics['tweet_count']\n",
        "                })\n",
        "            df_users = pd.DataFrame(user_data)\n",
        "\n",
        "            # Convert tweets to DataFrame\n",
        "            df_tweets = tweets_to_dataframe(tweets)\n",
        "\n",
        "            # Save data to CSV files\n",
        "            df_tweets.to_csv(f\"{search_query.replace(' ', '_')}_tweets.csv\", index=False)\n",
        "            df_users.to_csv(f\"{search_query.replace(' ', '_')}_users.csv\", index=False)\n",
        "\n",
        "            print(f\"Saved tweet data to '{search_query.replace(' ', '_')}_tweets.csv'\")\n",
        "            print(f\"Saved user data to '{search_query.replace(' ', '_')}_users.csv'\")\n",
        "\n",
        "            # Display sample of the data\n",
        "            print(\"\\nSample of tweet data:\")\n",
        "            print(df_tweets.head(3))\n",
        "\n",
        "            print(\"\\nSample of user data:\")\n",
        "            print(df_users.head(3))\n",
        "        else:\n",
        "            print(\"Could not retrieve user details\")\n",
        "    else:\n",
        "        print(\"No tweets found for this query\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sample Tweets:\n",
            "              tweet_id                                               text  \\\n",
            "0  1913171407833379034  RT @omoalhajaabiola: Master in Business Analyt...   \n",
            "1  1913171220226277705  â†’ Context. \\nâ†’ Full datasets. \\nâ†’ The studies ...   \n",
            "2  1913171217328021684  I'm a scientist.  \\nEvery time I see a viral h...   \n",
            "3  1913171215172141355  @Aruu2578 Lol ðŸ˜‚ umm well hey data science guy ...   \n",
            "4  1913171038612918426  RT @VigilantFox: NEW: RFK Jr. dismantles the m...   \n",
            "\n",
            "                  created_at            author_id  retweet_count  reply_count  \\\n",
            "0  2025-04-18 10:03:03+00:00  1185728337873899520              6            0   \n",
            "1  2025-04-18 10:02:18+00:00            282965354              0            1   \n",
            "2  2025-04-18 10:02:17+00:00            282965354              0            1   \n",
            "3  2025-04-18 10:02:17+00:00  1912298092046802944              0            0   \n",
            "4  2025-04-18 10:01:35+00:00  1890964286228353024            722            0   \n",
            "\n",
            "   like_count  quote_count  \n",
            "0           0            0  \n",
            "1           0            0  \n",
            "2           0            0  \n",
            "3           0            0  \n",
            "4           0            0  \n",
            "Sample Users:\n",
            "               user_id          name      username  followers_count  \\\n",
            "0  1185728337873899520      Dr_cupid    arthorjnr1              133   \n",
            "1  1912298092046802944       Vinayak  vinayakxlife                7   \n",
            "2  1890964286228353024           EBB  N3v3rR3tr3at              184   \n",
            "3  1519039071783251968   Robin Renee    Bidendummy             1453   \n",
            "4  1597269171833868291  KYLakeLife17  KYLakeLife17              688   \n",
            "\n",
            "   following_count  tweet_count  \n",
            "0             1322         8423  \n",
            "1               43           30  \n",
            "2              780         3826  \n",
            "3             2169        63479  \n",
            "4             1102          960  \n"
          ]
        }
      ],
      "source": [
        "# Load CSVs\n",
        "df_tweets = pd.read_csv(\"data_science_twitter_tweets.csv\")\n",
        "df_users = pd.read_csv(\"data_science_twitter_users.csv\")\n",
        "\n",
        "print(\"Sample Tweets:\")\n",
        "print(df_tweets.head())\n",
        "\n",
        "print(\"Sample Users:\")\n",
        "print(df_users.head())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
